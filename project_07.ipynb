{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание проекта:\n",
    "Отток клиентов\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам предоставлены данные о поведении клиентов и расторжении договоров с банком.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм работы:\n",
    "   1. Введение\n",
    "   2. Обзор и предобработка данных\n",
    "   3. Разделим данные на обучающую, валидационную и тестовую выборки\n",
    "   4. Обучим разные модели без учета дисбаланса в классах\n",
    "   5. Повторим пункт 4 с учетом дисбаланса\n",
    "   6. Общий вывод\n",
    "\n",
    "Описание данных\n",
    "Данные находятся в файле /datasets/Churn.csv\n",
    "\n",
    "\n",
    "Известно:\n",
    "\n",
    "    RowNumber — индекс строки в данных\n",
    "    CustomerId — уникальный идентификатор клиента\n",
    "    Surname — фамилия\n",
    "    CreditScore — кредитный рейтинг\n",
    "    Geography — страна проживания\n",
    "    Gender — пол\n",
    "    Age — возраст\n",
    "    Tenure — сколько лет человек является клиентом банка\n",
    "    Balance — баланс на счёте\n",
    "    NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "    HasCrCard — наличие кредитной карты\n",
    "    IsActiveMember — активность клиента\n",
    "    EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "Целевой признак:\n",
    "\n",
    "    Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор и предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и посмотрим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "YANDEX_DATASETS_PATH = 'https://code.s3.yandex.net/datasets/'\n",
    "dataset_folder = 'datasets'\n",
    "dataset_name = 'Churn.csv'\n",
    "\n",
    "#download dataset if not existed\n",
    "if not path.exists(dataset_folder + '/' + dataset_name):\n",
    "    #create dir if not existed\n",
    "    Path(dataset_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #download dataset\n",
    "    urllib.request.urlretrieve(YANDEX_DATASETS_PATH + dataset_name,\n",
    "                               dataset_folder + '/' + dataset_name)\n",
    "\n",
    "df = pd.read_csv(dataset_folder + '/' + dataset_name)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Имеются пропуски в параметре Tenure. Посмотрим гистограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c73bab1a4af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.hist(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вывод: целевой параметр 'Exited' имеет сильный перекос в сторону нулей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посмотрим значения категориальных столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим дупликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Заполним пропуски в 'Tenure' медианными значениями. Для этого посмотрим корреляцию этого параметра с остальными. На основании этого сделаем сводную таблицу через которую заполним пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.corr()['Tenure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Наибольшая корреляция из значимых признаков с 'IsActiveMember' и 'HasCrCard'. Заполним пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['Tenure'] = df.groupby(['IsActiveMember', 'HasCrCard' ])['Tenure'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Удалим ненужные признаки из датасета и выполним One-Hot Encoding категориальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посмотрим результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вывод: мы выполнили прямое кодирование категориальных признаков и заполнили пропуски. Целевой признак несбалансирован в сторону \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Разделение данных на обучающую, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Разделим данные на обучающую, валидационную и тестовую выборки. Для этого напишем функцию разделения выборки на обучающую и остальную. А остальную разделим на валидационную и тестовую. Функция возвращает словарь по каждой из выборок.\n",
    "Например:\n",
    "\n",
    "\n",
    " df_data['train']['X'] - это features обучающей выборки\n",
    "\n",
    "\n",
    " df_data['test']['y'] - это targets тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data to train, validation and test samples\n",
    "# train_rem_size is proportion between train and remain samples\n",
    "# valid_test_size is proportion between valid and test samples in remain part\n",
    "def split_train_valid_test(X, y, train_rem_size, valid_test_size):\n",
    "\n",
    "    #split to train and remain\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=train_rem_size, random_state=123)\n",
    "\n",
    "    #split to valid and test\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, train_size=valid_test_size, random_state=123)\n",
    "\n",
    "    df_data = {'train': {'X': X_train, 'y': y_train},\n",
    "               'valid': {'X': X_valid, 'y': y_valid},\n",
    "               'test': {'X': X_test, 'y': y_test}}\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Сделаем разделение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Exited'], axis=1)\n",
    "y = df['Exited'].copy()\n",
    "data = split_train_valid_test(X, y, 0.8, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вывод: мы разбили выборку на обучающую и остальную в пропорции 0.8 к 0.2. А остальную разбили попалам между валидационной и тестовой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Обучение моделей без учета дисбаланса в классах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Напишем функцию которая будет возвращать GridSearch для моделей LogisticRegression, DecisionTreeClassifier, RandomForestClassifier с заданными параметрами скоринга, класса весов, кол-ва исполняемых потоков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#return GridSearch for LogisticRegression, DecisionTreeClassifier, RandomForestClassifier with parameters\n",
    "def get_grid_params(\n",
    "                    depth=        10,\n",
    "                    est =         200,\n",
    "                    depth_step=   4,\n",
    "                    step_est =    10,\n",
    "                    scoring=      'f1',\n",
    "                    class_weight= None,\n",
    "                    njobs=        12,\n",
    "                    refit=        True):\n",
    "\n",
    "    pipeline = Pipeline([('clf', LogisticRegression(random_state=123))])\n",
    "    parameters = [\n",
    "        {\n",
    "            'clf': (LogisticRegression(random_state=123),),\n",
    "            'clf__class_weight': [class_weight]\n",
    "        }, {\n",
    "            'clf': (DecisionTreeClassifier(random_state=123),),\n",
    "            'clf__max_depth': range(1, depth, depth_step),\n",
    "            'clf__class_weight': [class_weight]\n",
    "\n",
    "        }, {\n",
    "            'clf': (RandomForestClassifier(random_state=123),),\n",
    "            'clf__n_estimators': range(1, est, step_est),\n",
    "            'clf__max_depth': range(1, depth, depth_step),\n",
    "            'clf__class_weight': [class_weight]\n",
    "\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return GridSearchCV(pipeline, parameters, scoring=scoring, n_jobs=njobs, refit=refit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Напишем функцию, которая фитит данные в полученный GridSearch и выводит информацию о лучшей модели: основные параметры, F1 и AUC-ROC метрики для валидационной и тестовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fit data in grid search and print best estimator parameters and\n",
    "# F1, AUC-ROC for valid and test samples\n",
    "def fit_and_results(data,\n",
    "                    grid_search):\n",
    "\n",
    "    grid_search.fit(data['train']['X'], data['train']['y'])\n",
    "    print('Best estimator parameters:')\n",
    "    print(grid_search.best_params_)\n",
    "    print('F1 valid score:')\n",
    "    print(grid_search.best_score_)\n",
    "    print('F1 test score:')\n",
    "    test_score = f1_score(grid_search.\n",
    "                          best_estimator_.\n",
    "                          predict(data['test']['X']), data['test']['y'])\n",
    "    print(test_score)\n",
    "    roc_valid_score = roc_auc_score(grid_search.\n",
    "                                    best_estimator_.\n",
    "                                    predict(data['valid']['X']), data['valid']['y'])\n",
    "    roc_test_score = roc_auc_score(grid_search.\n",
    "                                   best_estimator_.\n",
    "                                   predict(data['test']['X']), data['test']['y'])\n",
    "    print('AUC-ROC valid score:')\n",
    "    print(roc_valid_score)\n",
    "    print('AUC-ROC test score:')\n",
    "    print(roc_test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Получим наилучшую модель без учета дисбаланса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = get_grid_params(depth=30,\n",
    "                              depth_step=5,\n",
    "                              est=500,\n",
    "                              step_est=50,\n",
    "                              scoring='f1',\n",
    "                            )\n",
    "\n",
    "fit_and_results(data, grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вывод: наилучшая модель без учета дисбаланса оказалась RandomForestClassifier(max_depth=21, n_estimators=151) и показала на тестовой выборке f1 = 0.56 и AUC-ROC = 0.83\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Обучeние моделей c учетом дисбаланса в классах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Получим наилучшую модель c учетом дисбаланса, для этого укажем параметр class_weight равным 'balanced':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = get_grid_params(depth=17,\n",
    "                              depth_step=4,\n",
    "                              est=200,\n",
    "                              step_est=20,\n",
    "                              scoring='f1',\n",
    "                              class_weight='balanced',)\n",
    "\n",
    "fit_and_results(data, grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вывод: балансировка классов увеличила F1(0.635 против 0.56), но уменьшила AUC-ROC(0.76 против 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Попробуем улучшить параметры с помощью апсемплинга. Для этого найдем отношение между положительными и отрицательными таргетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "n_repeat = round(len(df[df['Exited'] == 0]) / len(df[df['Exited'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Сделаем функцию для реализации апсемплинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=123)\n",
    "\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Сделаем разделение и апсемплим обучающую выборку с помощью полученного соотношения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = split_train_valid_test(X, y, 0.8, 0.5)\n",
    "data['train']['X'], data['train']['y'] = upsample(data['train']['X'], data['train']['y'], n_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим полученное соотношение таргетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['train']['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Найдем наилучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = get_grid_params(depth=17,\n",
    "                              depth_step=4,\n",
    "                              est=200,\n",
    "                              step_est=20,\n",
    "                              scoring='f1',\n",
    "                              class_weight='balanced',)\n",
    "\n",
    "fit_and_results(data, grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вывод: апсемплинг немного увеличил F1 метрику(0.64 против 0.635), и AUC-ROC (0.77 против 0.76) на тестовой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Общий вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Мы провели исследование клиентской базы \"Бета-Банка\". Целью работы было построение модели прогнозирующей уход клиента в ближайшее время. Мы заполнили пропуски и разделили выборки на обучающую, валидационую и тестовую. Меняя модели и их гиперпараметры, мы старались получить максимальный показатель F1. По результатам исследования полученная модель обладает следующими показателями на тестовом семпле:\n",
    "\n",
    "\n",
    "RandomForestClassifier(max_depth=13, n_estimators=161, class_weight='balanced'):\n",
    "F1:      0.641\n",
    "AUC-ROC: 0.77\n",
    "\n",
    "\n",
    "Рекомендации: сделать выгрузку с отсутствием пропусков в параметре 'Tenure' и сбалансированную по целевому показателю 'Exited'"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1388,
    "start_time": "2021-11-02T09:35:26.076Z"
   },
   {
    "duration": 770,
    "start_time": "2021-11-02T09:35:27.467Z"
   },
   {
    "duration": 3236,
    "start_time": "2021-11-02T09:35:28.240Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-02T09:35:31.478Z"
   },
   {
    "duration": 34,
    "start_time": "2021-11-02T09:35:31.490Z"
   },
   {
    "duration": 28,
    "start_time": "2021-11-02T09:35:31.526Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-02T09:35:31.557Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-02T09:35:31.571Z"
   },
   {
    "duration": 43,
    "start_time": "2021-11-02T09:35:31.587Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-02T09:35:31.632Z"
   },
   {
    "duration": 18,
    "start_time": "2021-11-02T09:35:31.647Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-02T09:35:31.667Z"
   },
   {
    "duration": 50,
    "start_time": "2021-11-02T09:35:31.679Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-02T09:35:31.732Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-02T09:35:31.742Z"
   },
   {
    "duration": 304539,
    "start_time": "2021-11-02T09:35:31.754Z"
   },
   {
    "duration": 139670,
    "start_time": "2021-11-02T09:40:36.295Z"
   },
   {
    "duration": 13,
    "start_time": "2021-11-02T09:42:55.969Z"
   },
   {
    "duration": 8,
    "start_time": "2021-11-02T09:42:55.994Z"
   },
   {
    "duration": 41,
    "start_time": "2021-11-02T09:42:56.006Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-02T09:42:56.050Z"
   },
   {
    "duration": 200725,
    "start_time": "2021-11-02T09:42:56.063Z"
   },
   {
    "duration": 479,
    "start_time": "2021-11-02T10:08:56.372Z"
   },
   {
    "duration": 26650,
    "start_time": "2021-11-02T10:09:18.967Z"
   },
   {
    "duration": 1348,
    "start_time": "2021-11-02T10:09:52.279Z"
   },
   {
    "duration": 1332,
    "start_time": "2021-11-03T05:28:29.693Z"
   },
   {
    "duration": 298,
    "start_time": "2021-11-03T05:28:31.027Z"
   },
   {
    "duration": 3195,
    "start_time": "2021-11-03T05:28:31.327Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-03T05:28:34.524Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-03T05:28:34.535Z"
   },
   {
    "duration": 44,
    "start_time": "2021-11-03T05:28:34.549Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-03T05:28:34.595Z"
   },
   {
    "duration": 14,
    "start_time": "2021-11-03T05:28:34.609Z"
   },
   {
    "duration": 22,
    "start_time": "2021-11-03T05:28:34.627Z"
   },
   {
    "duration": 44,
    "start_time": "2021-11-03T05:28:34.651Z"
   },
   {
    "duration": 19,
    "start_time": "2021-11-03T05:28:34.698Z"
   },
   {
    "duration": 17,
    "start_time": "2021-11-03T05:28:34.720Z"
   },
   {
    "duration": 50,
    "start_time": "2021-11-03T05:28:34.739Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-03T05:28:34.791Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-03T05:28:34.803Z"
   },
   {
    "duration": 1371,
    "start_time": "2021-11-03T06:06:13.144Z"
   },
   {
    "duration": 298,
    "start_time": "2021-11-03T06:06:14.518Z"
   },
   {
    "duration": 3262,
    "start_time": "2021-11-03T06:06:14.843Z"
   },
   {
    "duration": 9,
    "start_time": "2021-11-03T06:06:18.107Z"
   },
   {
    "duration": 10,
    "start_time": "2021-11-03T06:06:18.119Z"
   },
   {
    "duration": 17,
    "start_time": "2021-11-03T06:06:18.131Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-03T06:06:18.181Z"
   },
   {
    "duration": 13,
    "start_time": "2021-11-03T06:06:18.195Z"
   },
   {
    "duration": 22,
    "start_time": "2021-11-03T06:06:18.210Z"
   },
   {
    "duration": 11,
    "start_time": "2021-11-03T06:06:19.080Z"
   },
   {
    "duration": 18,
    "start_time": "2021-11-03T06:06:20.008Z"
   },
   {
    "duration": 5,
    "start_time": "2021-11-03T06:06:23.065Z"
   },
   {
    "duration": 12,
    "start_time": "2021-11-03T06:06:25.707Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-03T06:06:29.789Z"
   },
   {
    "duration": 7,
    "start_time": "2021-11-03T06:06:31.270Z"
   },
   {
    "duration": 1155,
    "start_time": "2021-11-03T06:13:54.151Z"
   },
   {
    "duration": 214,
    "start_time": "2021-11-03T06:13:55.310Z"
   },
   {
    "duration": 475,
    "start_time": "2021-11-03T06:14:14.898Z"
   },
   {
    "duration": 305,
    "start_time": "2021-11-03T10:51:39.013Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
